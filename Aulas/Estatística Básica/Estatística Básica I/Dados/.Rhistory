mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Pclass, Sex2, Age, SibSp, Parch)
# Data splitting
# Observações de treinamento
tr <- sample.int(891, 623, replace= F)
dados_treino <- dados[tr,]
glimpse(dados_treino)
dados_teste <- dados[-tr,]
glimpse(dados_teste)
ajuste_reg_lin <- lm(Survived ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
classificacoes <- ifelse(prob_posteriori > 0.5, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$Grupo)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Regressão Linear ######################################
ajuste_reg_lin <- lm(Survived ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
table(dados$Age)
# Leitura dos dados
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_titanic_treino.csv', sep = ';', dec = ',') %>%
mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Survived, Pclass, Sex2, as.numeric(Age), SibSp, Parch)
glimpse(dados)
# Leitura dos dados
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_titanic_treino.csv', sep = ';', dec = ',') %>%
mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Survived, Pclass, Sex2, as.numeric(Age), SibSp, Parch)
glimpse(dados)
# Leitura dos dados
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_titanic_treino.csv', sep = ';', dec = ',') %>%
mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Survived, Pclass, Sex2, Age, SibSp, Parch)
glimpse(dados)
dados_predicao <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_titanic_teste.csv', sep = ';', dec = ',') %>%
mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Pclass, Sex2, Age, SibSp, Parch)
# Data splitting
# Observações de treinamento
tr <- sample.int(891, 623, replace= F)
dados_treino <- dados[tr,]
dados_teste <- dados[-tr,]
################################### Regressão Linear ######################################
ajuste_reg_lin <- lm(Survived ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
classificacoes <- ifelse(prob_posteriori > 0.5, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$Grupo)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Regressão Linear ######################################
ajuste_reg_lin <- lm(Survived ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
prob_posteriori
classificacoes <- ifelse(prob_posteriori > 0.5, 1, 0)
classificacoes
tab_confusao <- table(classificacoes, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################## Regressão Logística ######################################
ajuste_reg_log <- glm(Survived ~ .,
family = binomial(link = 'logit'), data = dados_treino)
# Proporção de 1's na amostra de treino
p <- mean(dados_treino$Survived)
p
# Predições da probabilidade a posteriori
log_chances <- predict.glm(ajuste_reg_log, newdata = dados_teste[, -1])
prob_posteriori <- exp(log_chances)/(1+exp(log_chances))
classificacoes <- ifelse(prob_posteriori > p, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Análise Discriminante Linear ##############################
library(DiscriMiner)
fit <- linDA(variables = dados_treino[, -1],
group = dados_treino$Survived)
length(dados_treino$Survived)
dim(dados_treino[,-1])
fit <- linDA(variables = dados_treino[, -1],
group = dados_treino$Survived)
glimpse(dados_treino)
dados_disc <- na.omit(dados_treino)
fit <- linDA(variables = dados_disc[, -1],
group = dados_disc$Survived)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
fit <- quaDA(variables = dados_disc[, -1],
group = dados_disc$Survived)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Árvore de classificação ##############################
set.seed(0)
library(rpart)
# Ajustar a árvore:
fit <- rpart(Survived ~ .,
method="class", data = dados_treino)
# poda:
melhorCp = fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
# cp é uma medida de complexidade da árvore, essencialmente
# proporcional ao número de folhas presentes. Este código
# escolhe o melhor cp via validação cruzada.
pfit <- prune(fit, cp = melhorCp)
# plotar árvore podada
pdf('G:/UNICID/Análise Discriminante/Aulas/grafico_teste_arvore.pdf', width = 9, height = 9)
plot(pfit)
text(pfit,use.n=FALSE,all=FALSE,cex=1.5)
dev.off()
predito_arvore = predict(pfit, dados_treino[,-1], type="class")
predito_arvore
classificao_arvore = predict(pfit, dados_treino[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$Survived)
classificao_arvore = predict(pfit, dados_treino[,-1], type="class")
classificacao_arvore = predict(pfit, dados_treino[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
classificacao_arvore = predict(pfit, dados_treino[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$Survived)
classificacao_arvore = predict(pfit, dados_teste[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### KNN ##############################
library(FNN)
ajuste = knn(train = dados_treino[,-1], test = dados_teste[,-1],
cl = dados_treino$Survived, k = 3)
tab_confusao <- table(ajuste, dados_teste$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
dados_knn <- na.omit(dados_treino)
ajuste = knn(train = dados_knn[,-1], test = dados_teste[,-1],
cl = dados_treino$Survived, k = 3)
library(FNN)
dados_knn <- na.omit(dados_treino)
ajuste = knn(train = dados_knn[,-1], test = dados_teste[,-1],
cl = dados_knn$Survived, k = 3)
dados_knn <- na.omit(dados_treino)
dados_teste_knn <- na.omit(dados_teste)
ajuste = knn(train = dados_knn[,-1], test = dados_teste_knn[,-1],
cl = dados_knn$Survived, k = 3)
tab_confusao <- table(ajuste, dados_teste_knn$Survived)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_doenca.csv', sep = ';', dec = ',')
glimpse(dados)
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_doenca.csv', sep = ';', dec = ',') %>%
select(Doenca = LO3, ANGEST, AH, IMP, TRIGS, COLS, IDADE1, SEXO)
dados <- na.omit(dados)
glimpse(dados)
0.7*1205
tr <- sample.int(1205, 843, replace= F)
dados_treino <- dados[tr,]
dados_teste <- dados[-tr,]
glimpse(dados_treino)
# Leitura dos dados
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_doenca.csv', sep = ';', dec = ',') %>%
select(DOENCA = LO3, ANGEST, AH, IMP, TRIGS, COLS, IDADE1, SEXO)
dados <- na.omit(dados)
# Data splitting
# Observações de treinamento
tr <- sample.int(1205, 843, replace= F)
dados_treino <- dados[tr,]
dados_teste <- dados[-tr,]
################################### Regressão Linear ######################################
ajuste_reg_lin <- lm(DOENCA ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
classificacoes <- ifelse(prob_posteriori > 0.5, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################## Regressão Logística ######################################
ajuste_reg_log <- glm(DOENCA ~ .,
family = binomial(link = 'logit'), data = dados_treino)
# Proporção de 1's na amostra de treino
p <- mean(dados_treino$DOENCA)
p
# Predições da probabilidade a posteriori
log_chances <- predict.glm(ajuste_reg_log, newdata = dados_teste[, -1])
prob_posteriori <- exp(log_chances)/(1+exp(log_chances))
classificacoes <- ifelse(prob_posteriori > p, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Análise Discriminante Linear ##############################
library(DiscriMiner)
dados_disc <- na.omit(dados_treino)
fit <- linDA(variables = dados_disc[, -1],
group = dados_disc$DOENCA)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################ Análise Discriminante Quadrática ##############################
fit <- quaDA(variables = dados_disc[, -1],
group = dados_disc$DOENCA)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### Árvore de classificação ##############################
set.seed(0)
library(rpart)
# Ajustar a árvore:
fit <- rpart(DOENCA ~ .,
method="class", data = dados_treino)
# poda:
melhorCp = fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
# cp é uma medida de complexidade da árvore, essencialmente
# proporcional ao número de folhas presentes. Este código
# escolhe o melhor cp via validação cruzada.
pfit <- prune(fit, cp = melhorCp)
# plotar árvore podada
pdf('G:/UNICID/Análise Discriminante/Aulas/grafico_teste_arvore.pdf', width = 9, height = 9)
plot(pfit)
text(pfit,use.n=FALSE,all=FALSE,cex=1.5)
dev.off()
# Classificação
classificacao_arvore = predict(pfit, dados_teste[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
################################### KNN ##############################
library(FNN)
ajuste = knn(train = dados_treino[,-1], test = dados_teste[,-1],
cl = dados_treino$DOENCA, k = 3)
tab_confusao <- table(ajuste, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_titanic_treino.csv', sep = ';', dec = ',') %>%
mutate(Sex2 = ifelse(Sex == 'male', 1, 0)) %>%
select(Survived, Pclass, Sex2, Age, SibSp, Parch)
glimpse(dados)
##############################################################################################
#
#                                  Análise Discriminante - Aula 2
#
##############################################################################################
# Pacotes para análise
library(dplyr)
set.seed(0)
# Leitura dos dados
dados <- read.csv('G:/UNICID/Análise Discriminante/Dados/dados_doenca.csv', sep = ';', dec = ',') %>%
select(DOENCA = LO3, ANGEST, AH, IMP, TRIGS, COLS, IDADE1, SEXO)
dados <- na.omit(dados)
# Data splitting
# Observações de treinamento
tr <- sample.int(1205, 843, replace= F)
dados_treino <- dados[tr,]
dados_teste <- dados[-tr,]
################################### Regressão Linear ######################################
ajuste_reg_lin <- lm(DOENCA ~ .,
data = dados_treino)
prob_posteriori <- predict.lm(ajuste_reg_lin, newdata = dados_teste[, -1])
classificacoes <- ifelse(prob_posteriori > 0.5, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
tab_confusao
44/(44+29)
219/(219+70)
219/(219+29)
70/(70+44)
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
################################## Regressão Logística ######################################
ajuste_reg_log <- glm(DOENCA ~ .,
family = binomial(link = 'logit'), data = dados_treino)
# Proporção de 1's na amostra de treino
p <- mean(dados_treino$DOENCA)
# Predições da probabilidade a posteriori
log_chances <- predict.glm(ajuste_reg_log, newdata = dados_teste[, -1])
prob_posteriori <- exp(log_chances)/(1+exp(log_chances))
classificacoes <- ifelse(prob_posteriori > p, 1, 0)
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
################################### Análise Discriminante Linear ##############################
library(DiscriMiner)
fit <- linDA(variables = dados_treino[, -1],
group = dados_treino$DOENCA)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
################################ Análise Discriminante Quadrática ##############################
fit <- quaDA(variables = dados_treino[, -1],
group = dados_treino$DOENCA)
# Classificando um novo objeto
classificacoes <- classify(fit, newdata = dados_teste[, -1])$pred_class
tab_confusao <- table(classificacoes, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
################################### Árvore de classificação ##############################
library(rpart)
# Ajustar a árvore:
fit <- rpart(DOENCA ~ .,
method="class", data = dados_treino)
# poda:
melhorCp = fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
# cp é uma medida de complexidade da árvore, essencialmente
# proporcional ao número de folhas presentes. Este código
# escolhe o melhor cp via validação cruzada.
pfit <- prune(fit, cp = melhorCp)
# plotar árvore podada
pdf('G:/UNICID/Análise Discriminante/Aulas/grafico_teste_arvore.pdf', width = 9, height = 9)
plot(pfit)
text(pfit,use.n=FALSE,all=FALSE,cex=1.5)
dev.off()
# Classificação
classificacao_arvore = predict(pfit, dados_teste[,-1], type="class")
tab_confusao <- table(classificacao_arvore, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
################################### KNN ##############################
library(FNN)
ajuste = knn(train = dados_treino[,-1], test = dados_teste[,-1],
cl = dados_treino$DOENCA, k = 3)
tab_confusao <- table(ajuste, dados_teste$DOENCA)
taxa_acertos <- (tab_confusao[1,1] + tab_confusao[2,2])/sum(tab_confusao)
taxa_acertos
sensibilidade <- tab_confusao[2,2]/(sum(tab_confusao[,2]))
sensibilidade
especificidade <- tab_confusao[1,1]/(sum(tab_confusao[,1]))
especificidade
vpn <- tab_confusao[1,1]/(sum(tab_confusao[1,]))
vpn
vpp <- tab_confusao[2,2]/(sum(tab_confusao[2,]))
vpp
require(binom)
require(binomSamSize)
# CONSTRUÇÃO DA TABELA
binom.wald <- function(x, n, conf.level){
binom.confint(x, n, conf.level, method = "asymptotic")}
binom.clopper <- function(x, n, conf.level){
binom.confint(x, n, conf.level, method = "exact")}
binom.wilson <- function(x, n, conf.level){
binom.confint(x, n, conf.level, method = "wilson")}
binom.agresticoull <- function(x, n, conf.level){
binom.confint(x, n, conf.level, method = "agresti-coull")}
#Calculando as probabilidades de cobertura
coverage_table <- function(n, alpha){
p <- seq(0,1,length=1000)[-c(1,1000)]
cov.wald <- coverage(binom.wald, n, alpha,
p.grid=p, interval=c(0,1))
min.wald <- min(cov.wald$probs)
mean.wald <- mean(cov.wald$probs)
cov.clopper <- coverage(binom.clopper, n, alpha,
p.grid=p, interval=c(0,1))
min.clopper <- min(cov.clopper$probs)
mean.clopper <- mean(cov.clopper$probs)
cov.wilson <- coverage(binom.wilson, n, alpha,
p.grid=p, interval=c(0,1))
min.wilson <- min(cov.wilson$probs[-1])
mean.wilson <- mean(cov.wilson$probs[-1])
cov.agresticoull <- coverage(binom.agresti.coull, n, alpha,
p.grid=p, interval=c(0,1))
min.agresticoull <- min(cov.agresticoull$probs)
mean.agresticoull <- mean(cov.agresticoull$probs)
cob.HPD.J <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "highest", prior.shape1 = 1/2,
prior.shape2 = 1/2)[4]
min.HPD.J <- min(cob.HPD.J$coverage)
mean.HPD.J <- mean(cob.HPD.J$coverage)
cob.central.J <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "central", prior.shape1 = 1/2,
prior.shape2 = 1/2)[4]
min.central.J <- min(cob.central.J$coverage)
mean.central.J <- mean(cob.central.J$coverage)
cob.HPD.U <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "highest", prior.shape1 = 1,
prior.shape2 = 1)[4]
min.HPD.U <- min(cob.HPD.U$coverage)
mean.HPD.U <- mean(cob.HPD.U$coverage)
cob.central.U <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "central", prior.shape1 = 1,
prior.shape2 = 1)[4]
min.central.U <- min(cob.central.U$coverage)
mean.central.U <- mean(cob.central.U$coverage)
cob.HPD.22 <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "highest", prior.shape1 = 2,
prior.shape2 = 2)[4]
min.HPD.22 <- min(cob.HPD.22$coverage)
mean.HPD.22 <- mean(cob.HPD.22$coverage)
cob.central.22 <- binom.coverage(p, n, conf.level = 1-alpha, method = "bayes",
type = "central", prior.shape1 = 2,
prior.shape2 = 2)[4]
min.central.22 <- min(cob.central.22$coverage)
mean.central.22 <- mean(cob.central.22$coverage)
return(data.frame(Intervalos = c('Wald', 'Clopper-Pearson', 'Wilson',
'Agresti-Coull', 'HPD Beta(2,2)',
'Central Beta(2,2)', 'HPD Jeffreys',
'Central Jeffreys', 'HPD Uniform',
'Central Uniform'),
Minimo = c(min.wald, min.clopper, min.wilson,
min.agresticoull, min.HPD.22,
min.central.22, min.HPD.J,
min.central.J, min.HPD.U,
min.central.U),
Media = c(mean.wald, mean.clopper, mean.wilson,
mean.agresticoull, mean.HPD.22,
mean.central.22, mean.HPD.J, mean.central.J,
mean.HPD.U, mean.central.U)))
}
cob_n5 <- coverage_table(n = 5, alpha = 0.05)
cob_n10 <- coverage_table(n = 10, alpha = 0.05)
cob_n30 <- coverage_table(n = 30, alpha = 0.05)
cob_n50 <- coverage_table(n = 50, alpha = 0.05)
cob_n100 <- coverage_table(n = 100, alpha = 0.05)
cob_n5
require(dplyr)
base_final <- cob_n5 %>%
bind_cols(cob_n10[, -1])
base_final
# Junção dos resultados
base_final <- cob_n5 %>%
bind_cols(cob_n10[, -1], cob_n30[, -1], cob_n50[, -1], cob_n100[, -1])
glimpse(base_final)
# Imprimindo tabela
write.table("C:/Users/Tuany/Dropbox/Mestrado/Artigo/Figuras/tab_1.csv", sep = ';', dec = ',')
?write.table
write.table(base_final, "C:/Users/Tuany/Dropbox/Mestrado/Artigo/Figuras/tab_1.csv", sep = ';', dec = ',')
# Imprimindo tabela
write.table(base_final, "C:/Users/Tuany/Dropbox/Mestrado/Artigo/Figuras/tab_1.csv", sep = ';', dec = ',', row.names = FALSE)
setwd("G:/UNICID/Estatística Básica I/Dados")
##############################################################################################
#
#                                     Estatística Descritiva
#                                     Tabelas de frequências
#
##############################################################################################
# Alterando diretório do R
setwd("G:/UNICID/Estatística Básica I/Dados")
# Instalando pacotes
require(dplyr)
# Leitura dos dados
dados <- read.csv('dados_cadastro.csv', sep=';', dec=',')
library(readr)
dados_cadastro <- read_delim("G:/UNICID/Estatística Básica I/Dados/dados_cadastro.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(dados_cadastro)
View(dados)
View(dados_cadastro)
library(readr)
dados <- read_delim("G:/UNICID/Estatística Básica I/Dados/dados_cadastro.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(dados)
# Instalando pacotes
require(dplyr)
# Impressão dos dados
glimpse(dados)
# Construindo tabela de frequências absolutas para Turma
tab_turma <- table(dados$Turma)
tab_turma
# Construindo tabela de frequências relativas para Turma
tab_turma_rel <- prop.table(tab_turma)
tab_turma_rel
# Tabela de frequências para Turma
tabela_turma <- dados %>%
count(Turma) %>%
mutate(prop = prop.table(n))
tabela_turma
